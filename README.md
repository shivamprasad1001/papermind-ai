
<p align="center">
  <img src="assets/PapermindAI_logo.png" alt="PaperMind AI" />
</p>
<p align= 'center'>
  
<img src="https://img.shields.io/badge/Powered%20By-LangChain-blueviolet?style=for-the-badge&logo=LangChain&logoColor=white" />
<img src="https://img.shields.io/badge/Model-TinyLLaMA-yellow?style=for-the-badge" />
<img src="https://img.shields.io/badge/Embeddings-MiniLM-lightgreen?style=for-the-badge" />
<img src="https://img.shields.io/badge/Vector%20Store-FAISS-blue?style=for-the-badge" />
<img src="https://img.shields.io/badge/Frontend-HTML/CSS/JS-orange?style=for-the-badge" />
<img src="https://img.shields.io/badge/Backend-FastAPI-teal?style=for-the-badge&logo=fastapi" />
<img src="https://img.shields.io/badge/License-MIT-informational?style=for-the-badge" />
<img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python" />

</p>
<h2 align="center">PaperMind AI</h2>

<p align="center">
An intelligent local-first PDF assistant that leverages Retrieval-Augmented Generation (RAG), LangChain, and powerful open-source language models to allow natural language interaction with documents ‚Äî securely and offline.
</p>

---

### üß† Overview

**PaperMind AI** is a local, privacy-focused PDF Chat Assistant that allows users to upload PDF files and ask natural language questions based on their content. It's powered by:

- **TinyLLaMA-1.1B-Chat-v1.0** for local chat inference
- **all-MiniLM-L6-v2** for semantic understanding and vector embeddings
- **FAISS** for fast vector search
- **LangChain** for orchestration of the RAG pipeline

Built with a modern, responsive **HTML/CSS/JS frontend** and **FastAPI backend**, PaperMind AI delivers a smooth and minimal experience akin to commercial AI tools ‚Äî but fully offline and transparent.

---

### üöÄ Features

- ‚úÖ Upload any PDF document
- ‚úÖ Ask questions naturally about the file
- ‚úÖ Local-first inference ‚Äî no cloud API keys required
- ‚úÖ Vector search powered by FAISS
- ‚úÖ RAG pipeline using LangChain
- ‚úÖ Minimal frontend with drag-and-drop UX
- ‚úÖ Modular backend (FastAPI) for extensibility

---

### üìÅ Project Structure

```

PaperMind-AI/
‚îú‚îÄ‚îÄ frontend/               # HTML, CSS, and JS assets for UI
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ styles.css
‚îÇ   ‚îî‚îÄ‚îÄ script.js
‚îú‚îÄ‚îÄ uploads/                # Stores uploaded PDF files
‚îú‚îÄ‚îÄ vectorstore/            # FAISS index for document chunks
‚îÇ   ‚îî‚îÄ‚îÄ index.faiss
‚îú‚îÄ‚îÄ app.py                  # FastAPI server with endpoints
‚îú‚îÄ‚îÄ ingest.py               # PDF ingestion & vectorization
‚îú‚îÄ‚îÄ chat.py                 # Query processing and RAG pipeline
‚îî‚îÄ‚îÄ README.md

````

---

### üì¶ Tech Stack

| Layer        | Technology                                  |
|--------------|---------------------------------------------|
| UI           | HTML, CSS, JavaScript                       |
| Backend      | FastAPI                                     |
| ML Models    | TinyLLaMA-1.1B-Chat-v1.0, all-MiniLM-L6-v2  |
| RAG Pipeline | LangChain                                   |
| Vector Store | FAISS                                       |
| Embedding    | Hugging Face Sentence Transformers          |

---

### üîß Installation

> Ensure you have Python 3.10+ and `virtualenv` set up.

```bash
git clone https://github.com/shivamprasad1001/PaperMind-AI.git
cd PaperMind-AI
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows
pip install -r requirements.txt
````

---

### ‚ñ∂Ô∏è Running the App

```bash
# Start the backend API server
uvicorn app:app --reload

# Then open the frontend/index.html in your browser
```

---

### üõ†Ô∏è Models Used

* [TinyLLaMA-1.1B-Chat-v1.0](https://huggingface.co/cognitivecomputations/TinyLlama-1.1B-Chat-v1.0)
* [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

These models are downloaded and loaded locally, ensuring full privacy and speed.

---

### üß™ API Endpoints

| Method | Endpoint       | Description                   |
| ------ | -------------- | ----------------------------- |
| POST   | `/upload-pdf/` | Upload and ingest a PDF file  |
| POST   | `/chat/`       | Query PDF using RAG inference |

---

### üõ°Ô∏è Privacy First

All computation is done locally. No data is sent to any external servers or APIs.

---

### üìå Roadmap

* [x] v1.0 ‚Äî Local PDF Chat Assistant
* [ ] v1.1 ‚Äî Multi-PDF ingestion
* [ ] v1.2 ‚Äî UI improvements & context memory
* [ ] v2.0 ‚Äî File upload via drag-and-drop in browser + Electron desktop app

---

### üß© Contributions

Contributions, issues, and suggestions are welcome. Please open a pull request or start a discussion!

---

### üìú License

MIT License ¬© 2025 Shivam Prasad

---


> Built with ‚ù§Ô∏è and a passion for open-source AI tools by [Shivam Prasad](https://github.com/shivamprasad1001)

